<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Measuring what Matters</title>
  <meta name="description" content="Construct Validity in Large Language Model Benchmarks" />
  <link rel="icon" href="../img/assets/checklist-icon.svg" type="image/svg+xml" />
  <link rel="shortcut icon" href="../img/assets/checklist-icon.svg" type="image/svg+xml" />
  <style>
    :root{
      --ink:#1f2937;        /* text */
      --muted:#6b7280;      /* secondary text */
      --link:#002147;       /* links */
      --bg:#ffffff;         /* page bg */
      --card:#ffffff;       /* section bg */
      --border:#e5e7eb;     /* borders */
      --accent:#0f172a;     /* headings */
      --maxw: 920px;
    }
    *{box-sizing:border-box}
    html,body{margin:0;padding:0;background:var(--bg);color:var(--ink);font:16px/1.7 system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,Apple Color Emoji,Segoe UI Emoji}
    a{color:var(--link);text-decoration:none}
    a:hover{text-decoration:underline}
    .container{max-width:var(--maxw);margin:0 auto;padding:2.5rem 1.25rem}
    header{padding-bottom:1rem;border-bottom:1px solid var(--border)}
    h1{font-size:clamp(1.9rem,3.8vw,2.6rem);line-height:1.2;margin:0 0 .5rem;color:var(--accent);font-weight:650;letter-spacing:-.01em}
    .meta{display:flex;flex-direction:column;gap:.5rem;margin:.75rem 0 0}
    .authors{font-size:1.02rem}
    .affils{color:var(--muted);font-size:.98rem}
    .badges{display:flex;flex-wrap:wrap;gap:.5rem;margin-top:.25rem}
    .badge{display:inline-block;font-size:.8rem;background:var(--card);border:1px solid var(--border);padding:.15rem .5rem;border-radius:.4rem;color:var(--muted)}
    main{display:grid;gap:1.25rem;margin-top:1.5rem}
    section{background:var(--card);border:1px solid var(--border);border-radius:.6rem;padding:1rem 1.25rem}
    section h2{margin:.25rem 0 .25rem;font-size:1.25rem;color:var(--accent)}
    .keywords{color:var(--muted);font-size:.95rem;margin-top:.5rem}
    .toc{font-size:.95rem;color:var(--muted)}
    .toc a{margin-right:1rem}
    code,pre,textarea{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}
    .bibtex{background:#0b1020;color:#e5e7eb;border-radius:.6rem;border:1px solid #111827;padding:0}
    .bibtex header{display:flex;justify-content:space-between;align-items:center;padding:.8rem 1rem;border:0;border-bottom:1px solid #1f2937}
    .bibtex h3{margin:0;font-size:1rem;color:#e5e7eb}
    .copy-btn{appearance:none;border:1px solid #334155;background:#111827;color:#e5e7eb;border-radius:.4rem;padding:.4rem .6rem;font-size:.85rem;cursor:pointer}
    .copy-btn:hover{background:#0b1324}
    .bibtex textarea{width:100%;height:8rem;max-height:16rem;overflow:auto;border:0;margin:0;padding:1rem;background:transparent;color:inherit;resize:vertical}
    footer{margin-top:2rem;color:var(--muted);font-size:.9rem;text-align:center}
    /* authors toggle */
    .meta-toggle{display:flex;align-items:baseline;gap:.75rem}
    .toggle-authors{appearance:none;border:0;background:none;color:var(--link);cursor:pointer;padding:0}
    .toggle-authors:hover{text-decoration:underline}
    /* collapsible styles no longer used */
    /* highlight tagline: make visually distinct */
    #highlight .rec-title{
      display:block;align-items:center;gap:.5rem;
      padding:.25rem .5rem;border-radius:.4rem;
      background:#fdecea;border:1px solid #f5c2c7;
    }
    /* spacing between collapsible paper sections */
    #paperDetails > section + section{margin-top:1rem}
    @media (prefers-color-scheme: dark){
      :root{--bg:#0b0f14;--ink:#e5e7eb;--muted:#94a3b8;--card:#0f172a;--border:#1f2937;--accent:#f3f4f6;--link:#60a5fa}
      header h4 a{color:#ffffff !important}
      /* dark mode styling for highlight tagline */
      #highlight .rec-title{
        background:#2a1214; /* deep muted red for contrast on dark */
        border-color:#7a2e34;
        color:var(--ink);
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <a class="back-btn" href="https://oxrml.com" rel="noopener noreferrer" aria-label="Back to oxrml.com">← Reasoning with Machines Lab</a>
      <h1>Measuring what Matters: Construct Validity in Large Language Model Benchmarks</h1>
      <h4 style="margin:0; display:flex; align-items:center; gap:.5rem;">
        <img src="../img/assets/NeurIPS-logo.svg" style="height:1.2em; vertical-align:middle; display:inline-block; margin-right:.4rem;" />
        <a href="https://neurips.cc/Conferences/2025" target="_blank" style="color: black"><i>NeurIPS 2025 Datasets and Benchmarks Track</i></a>
      </h4>

      <div class="meta">
        <div class="badges">
          <a class="badge" aria-label="arXiv"><img src="../img/assets/arxiv.svg" style="height:1.2em; vertical-align:middle; display:inline-block; margin-right:.4rem;">arXiv</a>
          <a class="badge" href="https://huggingface.co/datasets/ambean/construct-validity-review" aria-label="Hugging Face" target="_blank"><img src="../img/assets/hf.svg" style="height:1.2em; vertical-align:middle; display:inline-block; margin-right:.4rem;">Hugging Face</a>
          <a class="badge" href="checklist.html" aria-label="Checklist"><img src="../img/assets/checklist-icon.svg" style="height:1.2em; vertical-align:middle; display:inline-block; margin-right:.4rem;">Checklist</a>
        </div>
      </div>
      <br>
      <section id="highlight">
        <p style="padding-top:0;padding-bottom:.4rem;margin:0">LLM benchmarks are essential for tracking progress and ensuring safety in AI, but <strong>most benchmarks don't <i>measure what matters</i></strong>.</p>

        <p style="padding-top:0;padding-bottom:.4rem;margin:0">We reviewed 445 LLM benchmarks from the proceedings of top AI conferences. We found many measurement challenges, including vague definitions for target phenomena or an absence of statistical tests. We consider these challenges to the <i>construct validity</i> of LLM benchmarks: many benchmarks are not valid measurements of their intended targets.</p>
        
        <p style="padding-top:0;padding-bottom:.4rem;margin:0">We built a taxonomy of these failures and translated them into an operational checklist to help future benchmark authors demonstrate construct validity.</p>
        <span class="rec-title">
          <strong>Does your benchmark measure up?</strong> Compare against our <a href="checklist.html" style="color: #C15548; font-weight: bold">Construct Validity Checklist</a>.
        </span>
      </section>
    </header>

    <main>
        <div id="paperDetails">

        <section id="review-process" class="review-process" aria-labelledby="review-process-h">
            <h2 id="methods-h">Methods</h2>
            <p>We conducted a systematic review, as illustrated below. We began with 46,114 articles drawn from the proceedings of ICML, ICLR and NeurIPS (accessed via proceedings websites)  between 2018 and 2024, and from ACL, NAACL and EMNLP between 2020 and 2024 (accessed via ACL Anthology).</p>

            <p>We identified and selected articles whose titles or abstracts contained the keywords 'benchmark' and either 'LLM' or 'language model.' Then, we conducted a series of manual and automated filtering steps to select 445 articles included for final review.</p>
            <div class="iframe-wrapper">
                <img src="../img/assets/review-process.png" />
            </div>
            <p><b>Systematic review process.</b> (A) Identification and screening from relevant proceedings. (B) In-depth review and annotation of included benchmarks. A phenomenon is operationalised via a task, scored with a metric, to support a claim about this phenomenon. (C) Synthesis of best practices.</p>
        </section>

        <section id="diagram" class="diagram" aria-labelledby="diagram-h">
            <h2 id="diagram-h">Results</h2>

            <p>We reviewed each benchmark article with a twenty-one item questionnaire. Twenty-nine experts in NLP and ML contributed to this effort.</p>
            <div class="iframe-wrapper">
                <img src="../img/assets/benchmark_review_results_overview.png" />
            </div>
            <p><b>Summary of reviewed articles.</b> (A) Three most common categories of benchmark phenomena, grouped into general capabilities, general applications, and specific applications. (B) Number of articles by publication year and number which discuss the construct validity of their benchmark.</p>

            <div class="iframe-wrapper">
                <iframe src="benchmark_sankey.html"></iframe>
            </div>
            <p><b>Key codebook results.</b> The distribution of codebook responses on selected items. In each column, the options are ordered from most to least preferred for high construct validity. The shaded area indicates the benchmarks that follow the best practices for all five items.</p>
        </section>

      <section id="recommendations" class="recs" aria-labelledby="recs-h">
        <h2 id="recs-h">Construct validity checklist</h2>

        <p>Informed by our systematic review, we provide eight recommendations to ensure the construct validity of your benchmark:</p>

        <ul class="icon-list">
            <li>Define the phenomenon</li>
            <li>Measure only the phenomenon</li>
            <li>Construct a representative dataset for the task</li>
            <li>Acknowledge limitations of reusing datasets</li>
            <li>Prepare for contamination</li>
            <li>Use statistical methods to compare models</li>
            <li>Conduct an error analysis</li>
            <li>Justify construct validity</li>
        </ul>

        <p>See our interactable checklist, including PDF and LaTeX versions, on <a href="checklist.html" style="color: #C15548; font-weight: bold">this page</a>.</p>

        <!-- <div class="recs-grid">
            <fieldset class="rec">
            
            <h4 class="rec-title">Define the phenomenon</h4>
            <ul class="checklist">
                <li>
                <input id="rec1-1" type="checkbox" />
                <label for="rec1-1">Provide a precise and operational definition for the phenomenon being measured</label>
                </li>
                <li>
                <input id="rec1-2" type="checkbox" />
                <label for="rec1-2">Specify the scope of the phenomenon being covered and acknowledge any excluded aspects</label>
                </li>
                <li>
                <input id="rec1-3" type="checkbox" />
                <label for="rec1-3">Identify if the phenomenon has sub-components and ensure they are measured separately</label>
                </li>
            </ul>
            </fieldset>

            <fieldset class="rec">
            <h4 class="rec-title">Measure only the phenomenon</h4>
            <ul class="checklist">
                <li>
                <input id="rec2-1" type="checkbox" />
                <label for="rec2-1">Control for unrelated tasks that may affect the results</label>
                </li>
                <li>
                <input id="rec2-2" type="checkbox" />
                <label for="rec2-2">Assess the impact of format constraints on model performance</label>
                </li>
                <li>
                <input id="rec2-3" type="checkbox" />
                <label for="rec2-3">Validate any automated output parsing techniques for accuracy, consistency and bias</label>
                </li>
            </ul>
            </fieldset>

            <fieldset class="rec">
            <h4 class="rec-title">Construct a representative dataset for the task</h4>
            <ul class="checklist">
                <li>
                <input id="rec3-1" type="checkbox" />
                <label for="rec3-1">Employ sampling strategies to ensure task items are representative of the overall task space</label>
                </li>
                <li>
                <input id="rec3-2" type="checkbox" />
                <label for="rec3-2">Verify the quality and relevance of all task items especially for large or automatically generated datasets</label>
                </li>
                <li>
                <input id="rec3-3" type="checkbox" />
                <label for="rec3-3">Include task items that test known LLM sensitivities (e.g. input permutations or variations)</label>
                </li>
            </ul>
            </fieldset>

            <fieldset class="rec">
            <h4 class="rec-title">Acknowledge limitations of reusing datasets</h4>
            <ul class="checklist">
                <li>
                <input id="rec4-1" type="checkbox" />
                <label for="rec4-1">Document whether the benchmark adapts a previous dataset or benchmark</label>
                </li>
                <li>
                <input id="rec4-2" type="checkbox" />
                <label for="rec4-2">If so, analyse and report the relevant strengths and limitations of the adapted prior work</label>
                </li>
                <li>
                <input id="rec4-3" type="checkbox" />
                <label for="rec4-3">If so, report and compare performance on the new benchmark against the original</label>
                </li>
                <li>
                <input id="rec4-4" type="checkbox" />
                <label for="rec4-4">Explain modifications to reused datasets and how they improve construct validity</label>
                </li>
            </ul>
            </fieldset>

            <fieldset class="rec">
            <h4 class="rec-title">Prepare for contamination</h4>
            <ul class="checklist">
                <li>
                <input id="rec5-1" type="checkbox" />
                <label for="rec5-1">Implement tests to detect data contamination and apply them to the benchmark</label>
                </li>
                <li>
                <input id="rec5-2" type="checkbox" />
                <label for="rec5-2">Maintain a held-out set of task items to facilitate ongoing, uncontaminated evaluation</label>
                </li>
                <li>
                <input id="rec5-3" type="checkbox" />
                <label for="rec5-3">Investigate the potential pre-exposure of benchmark source materials or similar data in common LLM training corpora</label>
                </li>
            </ul>
            </fieldset>

            <fieldset class="rec">
            <h4 class="rec-title">Use statistical methods to compare models</h4>
            <ul class="checklist">
                <li>
                <input id="rec6-1" type="checkbox" />
                <label for="rec6-1">Report the benchmark's sample size and justify its statistical power</label>
                </li>
                <li>
                <input id="rec6-2" type="checkbox" />
                <label for="rec6-2">Report uncertainty estimates for all primary scores to enable robust model comparisons</label>
                </li>
                <li>
                <input id="rec6-3" type="checkbox" />
                <label for="rec6-3">If using human raters, describe their demographics and mitigate potential demographic biases in rater recruitment and instructions</label>
                </li>
                <li>
                <input id="rec6-4" type="checkbox" />
                <label for="rec6-4">Use metrics that capture the inherent variability of any subjective labels, without relying on single-point aggregation or exact matching</label>
                </li>
            </ul>
            </fieldset>

            <fieldset class="rec">
            <h4 class="rec-title">Conduct an error analysis</h4>
            <ul class="checklist">
                <li>
                <input id="rec7-1" type="checkbox" />
                <label for="rec7-1">Conduct a qualitative and quantitative analysis of common failure modes</label>
                </li>
                <li>
                <input id="rec7-2" type="checkbox" />
                <label for="rec7-2">Investigate whether failure modes correlate with non-targeted phenomena (confounders) rather than the intended construct</label>
                </li>
                <li>
                <input id="rec7-3" type="checkbox" />
                <label for="rec7-3">If so, identify and discuss any potential scoring biases revealed in the error analysis</label>
                </li>
            </ul>
            </fieldset>

            <fieldset class="rec">
            <h4 class="rec-title">Justify construct validity</h4>
            <ul class="checklist">
                <li>
                <input id="rec8-1" type="checkbox" />
                <label for="rec8-1">Justify the relevance of the benchmark for the phenomenon with real-world applications</label>
                </li>
                <li>
                <input id="rec8-2" type="checkbox" />
                <label for="rec8-2">Provide a clear rationale for the choice of tasks and metrics, connected to the operational definition of the phenomenon</label>
                </li>
                <li>
                <input id="rec8-3" type="checkbox" />
                <label for="rec8-3">Compare similarities and differences between the benchmark and existing evaluations of similar phenomena</label>
                </li>
                <li>
                <input id="rec8-4" type="checkbox" />
                <label for="rec8-4">Discuss the limitations and design trade-offs of the benchmark concerning construct validity</label>
                </li>
            </ul>
            </fieldset>
        </div> -->
        </section>
        </div>

        <style>
        /* subtle back button above header */
        .back-btn{
          display: inline-flex;
          align-items: center;
          gap: .5rem;
          font-size: .95rem;
          color: var(--muted);
          background: transparent;
          border: 1px solid transparent;
          padding: .35rem .6rem;
          border-radius: .5rem;
          text-decoration: none;
          margin-bottom: .75rem;
        }
        .back-btn:hover{
          color: var(--link);
          background: rgba(2,6,23,0.03);
          border-color: var(--border);
          text-decoration: none;
        }
        @media (prefers-color-scheme: dark){
          .back-btn{ color: var(--muted); }
          .back-btn:hover{ background: rgba(255,255,255,0.02); }
        }
        
        /* scoped styles */
        .iframe-wrapper {
            display: flex;
            justify-content: center;  /* centers horizontally */
            margin: 0 0;           /* optional spacing above/below */
        }

        .iframe-wrapper iframe {
            width: 100%;               /* adjust as needed (e.g. 100%, 60ch, etc.) */
            max-width: 900px;         /* keeps it from stretching too wide */
            height: 400px;            /* adjust to your content */
            border: none;             /* cleaner look */
        }

        .iframe-wrapper img {
            width: 80%;               /* adjust as needed (e.g. 100%, 60ch, etc.) */
            max-width: 900px;         /* keeps it from stretching too wide */
            height: 100%;            /* adjust to your content */
            border: none;             /* cleaner look */
        }


        .rec-title{
            display: inline-flex;              /* lay out icon + text on one line */
            align-items: center;
            gap: .5rem;                        /* space between icon and text */
            padding: 0 .5rem;                  /* keep the title inside the fieldset border */
        }

        .rec-title::before {
            content: "";
            display: inline-block;             /* participate in layout (no overlay) */
            inline-size: 1.1em;
            block-size: 1.0em;
            background: url("../img/assets/checklist-icon.svg") no-repeat center/contain;
        }

        .recs { margin-top: 1rem }
        .recs .recs-grid {
            display: grid;
            /* grid-template-columns: repeat(auto-fit, minmax(260px, 1fr)); */
            grid-template-columns: 1fr;
            gap: 1rem;
        }
        .recs .rec {
            border: 1px solid #e5e7eb;
            border-radius: .6rem;
            padding: .75rem .9rem 1rem;
            background: #f8fafc;
        }
        .recs .rec-title {
            font-weight: 600;
            color: #1f2937;
            margin: 0 0 .5rem;
            padding: 0;
        }
        /* icon list styling like rec-title */
        #recommendations .icon-list { list-style: none; margin: .25rem 0 0; padding: 0; padding-left: 1.5rem; display: grid; gap: .4rem; }
        #recommendations .icon-list li { position: relative; }
        #recommendations .icon-list li::before {
            content: "";
            position: absolute; left: -1.5rem; top: 0.3rem;
            inline-size: 1.1em; block-size: 1.1em;
            background: url("../img/assets/checklist-icon.svg") no-repeat center/contain;
        }
        .recs .checklist {
            list-style: none;
            padding: 0;
            padding-left: 1.5rem;
            margin: 0;
            display: grid;
            gap: .4rem;
        }
        .recs .checklist li {
            display: grid;
            grid-template-columns: auto 1fr;
            align-items: start;
            gap: .5rem;
        }
        .recs input[type="checkbox"] {
            inline-size: 1rem;
            block-size: 1rem;
            margin-top: .2rem;
            accent-color: #C15548; /* safe in modern browsers; ignored otherwise */
        }
        @media (prefers-color-scheme: dark){
            .recs .rec { background:#0f172a; border-color:#1f2937 }
            .recs .rec-title { color:#e5e7eb }
        }
</style>


<div id="authorsBlock">
  <div class="authors">
  <!-- Authors; use superscripts to tie to affiliations -->
  Andrew M. Bean<sup>1</sup>, Ryan Othniel Kearns<sup>1</sup>, Angelika Romanou<sup>2</sup>, 
  Franziska Sofia Hafner<sup>1</sup>, Harry Mayne<sup>1</sup>, 
  Jan Batzner<sup>3,4</sup>, Negar Foroutan<sup>2</sup>, Chris Schmitz<sup>5</sup>, 
  Karolina Korgul<sup>1</sup>, Hunar Batra<sup>1</sup>, 
  Oishi Deb<sup>1</sup>, Emma Beharry<sup>6</sup>, Cornelius Emde<sup>1</sup>, Thom Foster<sup>1</sup>, Anna Gausen<sup>7</sup>, 
  María Grandury<sup>8,9</sup>, Simeng Han<sup>10</sup>, Valentin Hofmann<sup>11,12</sup>, Lujain Ibrahim<sup>1</sup>, 
  Hazel Kim<sup>1</sup>, Hannah Rose Kirk<sup>1,7</sup>, Fangru Lin<sup>1</sup>, 
  Gabrielle Kaili-May Liu<sup>10</sup>, Lennart Luettgau<sup>7</sup>, Jabez Magomere<sup>1</sup>, Jonathan Rystrøm<sup>1</sup>, 
  Anna Sotnikova<sup>2</sup>, Yushi Yang<sup>1</sup>, Yilun Zhao<sup>10</sup>, 
  Adel Bibi<sup>1</sup>, Antoine Bosselut<sup>2</sup>, Ronald Clark<sup>1</sup>, Arman Cohan<sup>10</sup>, Jakob Foerster<sup>1</sup>, 
  Yarin Gal<sup>1,7</sup>, Scott A. Hale<sup>1,13</sup>, Inioluwa Deborah Raji<sup>14</sup>, Chris Summerfield<sup>1,7</sup>, 
  Philip H.S. Torr<sup>1</sup>, Cozmin Ududec<sup>7</sup>, Luc Rocher<sup>1</sup>, Adam Mahdi<sup>1</sup>
</div>

<div class="affils">
  <!-- Affiliations -->
  <sup>1</sup> University of Oxford &nbsp;·&nbsp;
  <sup>2</sup> EPFL &nbsp;·&nbsp;
  <sup>3</sup> Weizenbaum Institute Berlin &nbsp;·&nbsp;
  <sup>4</sup> Technical University Munich &nbsp;·&nbsp;
  <sup>5</sup> Centre for Digital Governance, Hertie School &nbsp;·&nbsp;
  <sup>6</sup> Stanford University &nbsp;·&nbsp;
  <sup>7</sup> UK AI Security Institute &nbsp;·&nbsp;
  <sup>8</sup> SomosNLP &nbsp;·&nbsp;
  <sup>9</sup> Universidad Politécnica de Madrid &nbsp;·&nbsp;
  <sup>10</sup> Yale University &nbsp;·&nbsp;
  <sup>11</sup> Allen Institute for AI &nbsp;·&nbsp;
  <sup>12</sup> University of Washington &nbsp;·&nbsp;
  <sup>13</sup> Meedan &nbsp;·&nbsp;
  <sup>14</sup> UC Berkeley
</div>
</div>
      <section class="bibtex" aria-labelledby="bibtex">
        <header>
          <h3 id="bibtex">Citation</h3>
          <button class="copy-btn" type="button" id="copyBib">Copy</button>
        </header>
        <textarea id="bibtexBox" readonly>
@inproceedings{
bean2025measuring,
title={Measuring what Matters: Construct Validity in Large Language Model Benchmarks},
author={Andrew M. Bean and Ryan Othniel Kearns and Angelika Romanou and Franziska Sofia Hafner and Harry Mayne and Jan Batzner and Negar Foroutan and Chris Schmitz and Karolina Korgul and Hunar Batra and Oishi Deb and Emma Beharry and Cornelius Emde and Thomas Foster and Anna Gausen and Mar{\'\i}a Grandury and Simeng Han and Valentin Hofmann and Lujain Ibrahim and Hazel Kim and Hannah Rose Kirk and Fangru Lin and Gabrielle Kaili-May Liu and Lennart Luettgau and Jabez Magomere and Jonathan Rystr{\o}m and Anna Sotnikova and Yushi Yang and Yilun Zhao and Adel Bibi and Antoine Bosselut and Ronald Clark and Arman Cohan and Jakob Nicolaus Foerster and Yarin Gal and Scott A. Hale and Inioluwa Deborah Raji and Christopher Summerfield and Philip Torr and Cozmin Ududec and Luc Rocher and Adam Mahdi},
booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2025},
url={https://openreview.net/forum?id=mdA5lVvNcU}
}
        </textarea>
      </section>
    </main>

    <footer>
      © 2025 Reasoning with Machines Lab, University of Oxford.
    </footer>
  </div>

  <script>
    // Copy BibTeX helper
    (function(){
      const btn = document.getElementById('copyBib');
      const box = document.getElementById('bibtexBox');
      if(btn && box){
        btn.addEventListener('click', async () => {
          try{
            await navigator.clipboard.writeText(box.value);
            btn.textContent = 'Copied!';
            setTimeout(()=> btn.textContent = 'Copy', 1200);
          }catch(e){
            // Fallback selection method
            box.select(); document.execCommand('copy');
            btn.textContent = 'Copied!';
            setTimeout(()=> btn.textContent = 'Copy', 1200);
          }
        });
      }
    })();

    // BibTeX box uses fixed height with scroll; autosize removed by request

    // Authors and paper details toggles removed; content always visible
  </script>
</body>
</html>
